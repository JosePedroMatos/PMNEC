{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb52973",
   "metadata": {},
   "source": [
    "# Parallel Work: Threads and Processes\n",
    "\n",
    "When to use threads vs processes, how to handle shared state, and practical examples using `concurrent.futures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ca47977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import threading\n",
    "from queue import Queue\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f4b3e",
   "metadata": {},
   "source": [
    "## Choosing Threads vs Processes\n",
    "- Python threads share memory and are great for I/O-bound work (waiting on disk/network). The GIL prevents multiple threads from running Python bytecode simultaneously.\n",
    "- Processes sidestep the GIL for CPU-bound work; they do not share memory, so use picklable arguments/results.\n",
    "- Rule of thumb: I/O → threads; CPU → processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61794b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logical CPUs: 24\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logical CPUs: {os.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dffb643",
   "metadata": {},
   "source": [
    "## I/O-Bound Work with Threads\n",
    "Use `ThreadPoolExecutor` when tasks mostly wait on I/O (network, disk, sleep)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5980278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received item-0\n",
      "received item-1\n",
      "received item-2\n",
      "received item-3\n",
      "received item-4\n",
      "received item-5\n",
      "received item-6\n",
      "received item-7\n",
      "received item-8\n",
      "received item-9\n",
      "Threaded I/O finished in 0.80s\n",
      "received item-5\n",
      "received item-6\n",
      "received item-7\n",
      "received item-8\n",
      "received item-9\n",
      "Threaded I/O finished in 0.80s\n"
     ]
    }
   ],
   "source": [
    "def fake_download(idx: int) -> str:\n",
    "    time.sleep(0.4)  # simulate waiting on network\n",
    "    return f\"item-{idx}\"\n",
    "\n",
    "start = time.perf_counter()\n",
    "with ThreadPoolExecutor(max_workers=5) as pool:\n",
    "    for result in pool.map(fake_download, range(10)):\n",
    "        print(\"received\", result)\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"Threaded I/O finished in {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3009865",
   "metadata": {},
   "source": [
    "## CPU-Bound Work with Processes\n",
    "`ProcessPoolExecutor` bypasses the GIL. Use picklable callables/arguments. Guard with `if __name__ == \"__main__\"` on Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fa24baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process pool demo is meant to run from a fresh kernel or CLI; restart kernel then call run_prime_pool(), or run `python 04.parallel.py`.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "def is_prime(n: int) -> bool:\n",
    "    if n < 2:\n",
    "        return False\n",
    "    if n % 2 == 0:\n",
    "        return n == 2\n",
    "    limit = int(math.sqrt(n)) + 1\n",
    "    for i in range(3, limit, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def count_primes_up_to(n: int) -> int:\n",
    "    # add a tiny delay to keep processes busy for a notable amount of time\n",
    "    time.sleep(0.05)\n",
    "    return sum(1 for x in range(n) if is_prime(x))\n",
    "\n",
    "\n",
    "def run_prime_pool(workers: int | None = None):\n",
    "    workers = workers or os.cpu_count()\n",
    "    inputs = [150_000 + i * 5_000 for i in range(workers)]\n",
    "    start = time.perf_counter()\n",
    "    ctx = multiprocessing.get_context(\"spawn\")\n",
    "    with ProcessPoolExecutor(max_workers=workers, mp_context=ctx) as pool:\n",
    "        counts = list(pool.map(count_primes_up_to, inputs))\n",
    "    elapsed = time.perf_counter() - start\n",
    "    for n, count in zip(inputs, counts):\n",
    "        print(f\"Primes below {n:,}: {count}\")\n",
    "    print(f\"Process pool completed in {elapsed:.2f}s using {workers} workers\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if \"get_ipython\" in globals():\n",
    "        print(\"Process pool demo is meant to run from a fresh kernel or CLI; restart kernel then call run_prime_pool(), or run `python 04.parallel.py`.\")\n",
    "    else:\n",
    "        multiprocessing.freeze_support()\n",
    "        multiprocessing.set_start_method(\"spawn\", force=True)\n",
    "        run_prime_pool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217880c7",
   "metadata": {},
   "source": [
    "## Shared State and Locks (Threads)\n",
    "Threads share memory. Use locks to protect shared state; prefer message passing (queues) when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dd24990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter = 500000 (expected 500000)\n",
      "Locked increments completed in 0.07s\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def add_many(n: int):\n",
    "    global counter\n",
    "    for _ in range(n):\n",
    "        with lock:\n",
    "            counter += 1\n",
    "\n",
    "threads = [threading.Thread(target=add_many, args=(100_000,)) for _ in range(5)]\n",
    "start = time.perf_counter()\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"Counter = {counter} (expected 500000)\")\n",
    "print(f\"Locked increments completed in {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d9de6a",
   "metadata": {},
   "source": [
    "## Producer/Consumer with Queue\n",
    "Use a `Queue` to safely hand off work between threads without manual locks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "689cf7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results (unordered):\n",
      "('worker-2', 'task-2')\n",
      "('worker-1', 'task-1')\n",
      "('worker-0', 'task-0')\n",
      "('worker-2', 'task-3')\n",
      "('worker-1', 'task-4')\n"
     ]
    }
   ],
   "source": [
    "q: Queue[str] = Queue()\n",
    "results = []\n",
    "\n",
    "# Producer\n",
    "for i in range(5):\n",
    "    q.put(f\"task-{i}\")\n",
    "\n",
    "# Consumers\n",
    "\n",
    "def worker(name: str):\n",
    "    while True:\n",
    "        try:\n",
    "            item = q.get_nowait()\n",
    "        except Exception:\n",
    "            break\n",
    "        time.sleep(0.1)\n",
    "        results.append((name, item))\n",
    "        q.task_done()\n",
    "\n",
    "threads = [threading.Thread(target=worker, args=(f\"worker-{i}\",)) for i in range(3)]\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"Results (unordered):\")\n",
    "for entry in results:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f34d41",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Threads excel at I/O-bound tasks; processes excel at CPU-bound tasks.\n",
    "- Protect shared state with locks or, better, avoid sharing via queues.\n",
    "- For CPU pools on Windows, keep pool creation under `if __name__ == \"__main__\"`.\n",
    "- Keep functions small and picklable for process pools."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
